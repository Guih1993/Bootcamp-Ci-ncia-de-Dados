# -*- coding: utf-8 -*-
"""Análise de dados com Python e Pandas.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GATfCibQa7kLp6DmI_utB5KEfU4WPrfo

# **Trabalhando com Planilhas no Excel**
"""

import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/datasets/Gapminder.csv" ,error_bad_lines=False, sep=";")

#visualisar as 5 primeiras linhas
df.head()
#visualizar as 5 ultimas linhas
df.tail()

df = df.rename(columns={"country":"Pais", "continent":"Continente", "year":"Ano", "lifeExp":"Expec.Vida","pop":"População","gdpPercap":"PIB"})

#Total de linhas/colunas
df.shape
#Retorna o cabeçalho/colunas
df.columns
#Retorna o tipo de dados das colunas
df.dtypes

#retorna informaçoes estatisticas dos dados (MUITO PIKA)
#count = contagem mean = media = std = desvio padrão min = minimo/menor 25%50%75% = quartis max = maximo/maior
df.describe()

df["Continente"].unique()

Oceania = df.loc[df["Continente"] == "Oceania"]
Oceania.head()

Oceania["Continente"].unique()

#agrupar por tipo
df.groupby("Continente")["Pais"].nunique()

df.groupby("Ano")["Expec.Vida"].mean()

#Leitura dos arquivos
df1 = pd.read_excel("Aracaju.xlsx")
df2 = pd.read_excel("Fortaleza.xlsx")
df3 = pd.read_excel("Natal.xlsx")
df4 = pd.read_excel("Recife.xlsx")
df5 = pd.read_excel("Salvador.xlsx")

#juntado todos os arquivos
dg = pd.concat([df1,df2,df3,df4,df5])

#Exibindo as 5 primeiras linhas
dg.head()

#exibindo as 5 ultimas linhas
dg.tail()

#exibir amostra do conjunto de dados (MUITO UTIL)
dg.sample(10)

#verificando os tipos de dados de cada coluna
dg.dtypes

#alterando o tipo de dado das colunas
dg["LojaID"] =dg["LojaID"].astype("object")

#consultando valores nulos
dg.isnull().sum()

#substituir valores nulos pela media
dg["Vendas"].fillna(dg["Vendas"].mean(), inplace=True)

dg["Vendas"].mean() #<<<<<<<<<formula da média ^^^^observe a estrutura da função

#preencher linhas com valores nulos com 0 
dg["Vendas"].fillna(0,inplace=True)

#apagar linhas com valores nulos em todo o conjunto de dados
dg.dropna(inplace=True)

#apagar as linhas com valores nulos apenas na coluna desejada
dg.dropna(subset=["Vendas"],inplace=True)

#criar a coluna de receita
dg["Receita"] = dg["Vendas"].mul(dg["Qtde"])
dg["Receita/Vendas"] = dg["Receita"] / dg["Vendas"]
dg.head()

#Retornando a maior receita
dg["Receita"].max()

#Retornando a menor receita
dg["Receita"].min()

#Retorna os top de uma determinada coluna
dg.nlargest(3, "Receita")

#Retorna os menores de uma determinada coluna
dg.nsmallest(3,"Receita")

#Agrupar por cidade (soma de receita por cidade)
dg.groupby("Cidade")["Receita"].sum()

#ordenar o conjunto de dados
dg.sort_values("Receita", ascending=False).head(10)

"""# **Trabalhando com Datas**"""

#transformando a coluna de data em tipo inteiro
dg['Data'] = dg['Data'].astype("int64")

dg.dtypes

#transformando a coluna de data em data
dg['Data'] = pd.to_datetime(dg['Data'])

#agrupando por ano
dg.groupby(dg['Data'].dt.year)["Receita"].sum()

#Criando uma nova coluna com o ano
dg["Ano_Venda"] = dg["Data"].dt.year

dg.sample(10)

#Extraindo o mes e o dia
dg["Mes_venda"], dg["Dia_venda"] = (dg["Data"].dt.month, dg["Data"].dt.day)

#retornando a data mais antiga
dg["Data"].min()

#calculando a diferença de dias
dg["diferenca_dias"] = dg['Data'] - dg['Data'].min()

#criando a coluna de semestre
dg["trimestre_venda"] = dg['Data'].dt.quarter

#filtrando as vendas
dg.loc[(dg['Data'].dt.year ==2019) & (dg['Data'].dt.month ==3)]

"""# **Visualização de Dados**"""

dg["LojaID"].value_counts(ascending=False)

#Grafico de barras
dg['LojaID'].value_counts(ascending=False).plot.bar();

#grafico de barras horizontais
dg['LojaID'].value_counts(ascending=True).plot.barh();

#grafico de pizza
dg.groupby(dg['Data'].dt.year)["Receita"].sum().plot.pie();

#total de vendas por cidade
dg["Cidade"].value_counts()

#adicionando um titulo e alterando o nome dos eixos
import matplotlib.pyplot as plt
dg["Cidade"].value_counts().plot.bar(title="Total de vendas por Cidade", color="red")
plt.xlabel("Cidade")
plt.ylabel("Total de vendas");

#alterando o estilo
plt.style.use("ggplot")

dg.groupby(dg["Mes_venda"])["Qtde"].sum().plot(title = "Total de produtos vendidos por mês")
plt.xlabel("Mês")
plt.ylabel("Total Produtos Vendidos")
plt.legend()

dg.groupby(dg['Mes_venda'])["Qtde"].sum()

#selecionando apenas vendas de 2019
dg_2019 = dg[dg["Ano_Venda"]== 2019]

dg_2019.groupby(dg_2019["Mes_venda"])["Qtde"].sum().plot(marker = "v")
plt.xlabel("Mês")
plt.ylabel("Total Produtos Vendidos")
plt.legend()

#histograma
plt.hist(dg["Qtde"]);

#Dispersão
plt.scatter(x=dg_2019["Dia_venda"], y = dg_2019["Receita"]);
plt.savefig("Grafico de dispersão")

"""# **Análise Explorátoria**"""

#importando as bibliotecas
import pandas as pd
import matplotlib.pyplot as plt
plt.style.use('seaborn')

#upload de arquivo
from google.colab import files
arq = files.upload()

#criando dataframe
da = pd.read_excel("AdventureWorks.xlsx")

#visualizando as 5 primeiras linhas
da.head()

#quantidade de linhas
da.shape

#verificando os tipos de dados
da.dtypes

#qual a receita total
da["Valor Venda"].sum()

#Criando coluna de Custo
da["Custo"] = da["Custo Unitário"].mul(da["Quantidade"])

#Qual o custo total
round(da["Custo"].sum(), 2)

#Coluna de lucro = Receita - Custo
da["Lucro"] = da["Valor Venda"] - da["Custo"]

#Total de Lucro
round(da["Lucro"].sum(), 2)

#Criando coluna com total de dias para enviar o produto
da["Tempo_envio"] = (da["Data Envio"] - da["Data Venda"]).dt.days #<<<< importante converter em dias senão vira string

#media de tempo de envio por marca
da.groupby("Marca")["Tempo_envio"].mean()

#verificando valores vazios
da.isnull().sum()

#agrupar por ano e marca
da.groupby([da["Data Venda"].dt.year, "Marca"])["Lucro"].sum()

pd.options.display.float_format = "{:20,.2f}".format

#resetando o index
lucro_ano = da.groupby([da["Data Venda"].dt.year, "Marca"])["Lucro"].sum().reset_index()
lucro_ano

#Qual o totak de produtos vendidos?
da.groupby("Produto")["Quantidade"].sum().sort_values(ascending=False)

#Grafico de total de produtos
da.groupby("Produto")["Quantidade"].sum().sort_values(ascending=True).plot.barh(title = "Total de Produtos Vendidos")
plt.xlabel("Total")
plt.ylabel("Produto");

da.groupby(da["Data Venda"].dt.year)["Lucro"].sum().plot.bar(title = "Lucro x Ano")
plt.xlabel('Ano')
plt.ylabel("Lucro");

da.groupby(da["Data Venda"].dt.year)["Lucro"].sum()

#selecionando apenas vendas de 2009
da_2009 = da[da["Data Venda"].dt.year == 2009]

da_2009.head()

da_2009.groupby(da_2009["Data Venda"].dt.month)["Lucro"].sum().plot(title="Lucro x Mês")
plt.xlabel("Mês")
plt.ylabel("Lucro");

da_2009.groupby("Marca")["Lucro"].sum().plot.bar(title="Lucro x Marca")
plt.xlabel("Marca")
plt.ylabel("Lucro")
plt.xticks(rotation = "horizontal");

da_2009.groupby("Classe")["Lucro"].sum().plot.bar(title="Lucro x Classe")
plt.xlabel("Classe")
plt.ylabel("Lucro")
plt.xticks(rotation = "horizontal");

da["Tempo_envio"].describe()

#Grafico de boxplot
plt.boxplot(da["Tempo_envio"]);

#histograma
plt.hist(da["Tempo_envio"]);

#tempo minimo de envio
da["Tempo_envio"].min()

#tempo maximo de envio
da["Tempo_envio"].max()

#indentificar o outlier
da[da["Tempo_envio"] == 20]

da.to_csv("da_vendas_novo.csv", index=False)